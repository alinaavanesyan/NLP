{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Alina Avanesyan*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Корпус**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве корпусных данных были взяты стихи, в которых удалось найти следующие группы слов, представляющих собой трудности для автоматического потсттеггинга:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Омонимы (дали (*сущ.*) - дали (*гл.*), лаем (*сущ., Т.п., ед.ч.*) - лаем (*гл.*)) (сложность в том, что написание слов идентичное, а часть речи можно определить только в контексте)\n",
    "- Слова с дефисным написанием (имена собственные (*Сант-Яго*), составные числительные (*десяти-двенадцати*))\n",
    "- Причастия/прилагательные (прошедшего, текущая)\n",
    "- Слова, придуманные автором (*громадьё*, *разжелудясь*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "#открываем файл с подготовленными текстами и записываем тексты в строку\n",
    "data = ''\n",
    "with open('data.txt', mode='r', encoding='UTF-8') as file:\n",
    "    for line in file.readlines():\n",
    "        data += line.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "621"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#количество токенов\n",
    "len(data.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#открываем таблицу со сложными для определения части речи словами\n",
    "diffic = pd.read_excel('dif_forms.xlsx')\n",
    "diffic['POS'] = diffic['POS'].apply(lambda x: x[1:-1].split(',') if '[' in x else x)\n",
    "forms = diffic['Словоформа'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве тегсета был выбран набор граммем от pymorphy2. Его удобство в том, что состав тегов хорошо описывает языковые особенности (например, в нем фиксируется существование причастий двух видов - полных и кратких, а также отдельно отмечается деепричастие. То есть глагольные формы не объединяются в один тег), необходимые для предотвращения неправильного теггинга. В нем не фиксируются классы местоимений (существует только местоимение-сущ., а остальные виды уже причисляют к другим граммемам (например, прил.)), однако стоит учитывать, что сложности с определением части речи чаще возникают при работе с глагольными формами, нежели чем с местоименными (поскольку число местоименных формы ограничено, они менее подвержены омонимии)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Разные POS теггеры** + конвертация тегов к единой системе тегов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.1. Pymorphy2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку у Pymorphy2 нет встроенного токенизатора, воспользуемся токенизатором NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stops = set(stopwords.words('russian'))\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/russian.pickle')\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = nltk.word_tokenize(data)\n",
    "\n",
    "pymorphy2_tags = {}\n",
    "for word in list(set(result)):\n",
    "    if word in forms or word.lower() in forms:\n",
    "        pymorphy2_tags[word] = morph.parse(word)[0].tag.POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "тут не происходит разделения, т.к. у pymorphy2 нет токенизатора, а nltk не разделяет слова по дефисам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.2. Mystem**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для экономии памяти компьютера и ускорения алгоритма встраиваем конвертер в процесс \"прогона\" текста через теггер. Можно было сначала прогнать текст, затем отдельной функции перевести одни теги в другие, согласно словарю. Однако в случае с Mystem, здесь отсутствуют теги для причастий, деепричастий, кратких/полных форм прилагательных/наречий и др. --> просто словарем в данном случае не обойтись, необходимо придумать алгоритм сложнее.\n",
    "\n",
    "Заметим, что по грамматической хар-ки слова, выдаваемой Mystem, можно определить форму. Например, в случае ниже слову присваивается тег \"VERB\" (глагол), однако в разделе verb_form содержится признак \"прич,полн\", который нам нужен вытащить (аналогично и с остальными категориями, отсутствующими в тегсете Mystem):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analysis': [{'lex': 'бежать',\n",
       "   'wt': 1,\n",
       "   'gr': 'V,нп=(непрош,вин,ед,прич,полн,муж,несов,действ,неод|непрош,им,ед,прич,полн,муж,несов,действ)'}],\n",
       " 'text': 'бегущий'}"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "\n",
    "ana = m.analyze('бегущий по дороге')\n",
    "ana[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#словарь для конвертации (слева - mystem, справа - варианты тегов в pymorphy2_tags\n",
    "mystem_pos = {\n",
    "    'A': {'positive': 'ADJF', 'short': 'ADJS', 'compar': 'COMP'},\n",
    "    'ADV': {'ordinary': 'ADV', 'predicative': 'PRED', 'compar': 'COMP'},\n",
    "    'S': 'NOUN',\n",
    "    'V': {'fin': 'VERB', 'inf': 'INFN', 'full_participle': 'PRTF', 'short_participle': 'PRTS', 'adverbial_participle': 'GRND'},\n",
    "    'PR': 'ADP', #перед\n",
    "    'INTJ': 'INTJ',\n",
    "    'PART': 'PART', #лишь\n",
    "    'NUM': 'NUM', #семь\n",
    "    'ADVPRO': 'ADV', #здесь\n",
    "    'APRO': 'PRON', #какой-то\n",
    "    'SPRO': 'PRON', #ты, некто\n",
    "    'ANUM': 'ADJ', #второй\n",
    "    'CONJ': 'CONJ', #и\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "\n",
    "mystem_tags = {}\n",
    "ana = m.analyze(data)\n",
    "\n",
    "for word in ana:\n",
    "    if word['text'] in forms or word['text'].lower() in forms:\n",
    "        if 'analysis' in word:\n",
    "            gr = word['analysis'][0]['gr']\n",
    "            tag = gr.split('=')[0].split(',')[0]\n",
    "            mystem_tags[word['text']] = tag\n",
    "\n",
    "            if tag == 'ADV':\n",
    "                if 'прдк' in gr:\n",
    "                    tag = mystem_pos['ADV']['predicative']\n",
    "                    \n",
    "                elif 'срав' in gr:\n",
    "                        tag = mystem_pos['ADV']['compar']\n",
    "                else:\n",
    "                    tag = mystem_pos['ADV']['ordinary']\n",
    "\n",
    "            elif tag == 'V':\n",
    "                if 'инф' in gr:\n",
    "                    tag = mystem_pos['V']['inf']\n",
    "                elif 'прич' in gr:\n",
    "                    if 'полн' in gr:\n",
    "                        tag = mystem_pos['V']['full_participle']\n",
    "                    else:\n",
    "                        tag = mystem_pos['V']['short_participle']\n",
    "                elif 'деепр' in gr:\n",
    "                    tag = mystem_pos['V']['adverbial_participle']\n",
    "                else:\n",
    "                    tag = mystem_pos['V']['fin']\n",
    "            \n",
    "            elif tag == 'A':\n",
    "                if 'кр' in gr:\n",
    "                    tag = mystem_pos['A']['short']\n",
    "                elif 'срав' in gr:\n",
    "                    tag = mystem_pos['A']['compar']\n",
    "                else:\n",
    "                    tag = mystem_pos['A']['positive']\n",
    "\n",
    "            else:\n",
    "                if tag in mystem_pos.keys():\n",
    "                    tag = mystem_pos[tag]           \n",
    "\n",
    "                \n",
    "            mystem_tags[word['text']] = tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что еще до этапа определения части речи Mystem определяет границы слова (парсит текст), поэтому слова с дефисами библиотека может поделить на два отдельных слова, например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'двадцать', 'wt': 1, 'gr': 'NUM=(пр|дат|род)'}],\n",
       "  'text': 'двадцати'},\n",
       " {'text': '-'},\n",
       " {'analysis': [{'lex': 'тридцать', 'wt': 1, 'gr': 'NUM=(пр|дат|род)'}],\n",
       "  'text': 'тридцати'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = 'двадцати-тридцати'\n",
    "m.analyze(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ручной заметке я тоже разделила эту форму на две отдельных, однако необходимо проверить совпадение тегов в списке тегов для каждой отдельной части, чтобы в дальнейшем оценивать accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in forms:\n",
    "    if f in data and len(m.analyze(f)) > 2 and m.analyze(f)[1]['text'] == '-':\n",
    "        new_tags = []\n",
    "        for t in m.analyze(f):\n",
    "            if 'analysis' in t:\n",
    "                gr = t['analysis'][0]['gr']\n",
    "                pos = gr.split('=')[0].split(',')[0]\n",
    "                new_tags.append(pos)\n",
    "        mystem_tags[f] = new_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае с pymorphy2 нам не нужно проводить подобные манипуляции, так как парсер от nltk обычно не разделяет слова с дефисами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.3. Natasha**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "natasha_pos = {\n",
    "    'ADJ': {'full': 'ADJF', 'short': 'ADJS', 'compar': 'COMP'},\n",
    "    'ADV': {'positive': 'ADVB', 'compar': 'COMP'},\n",
    "    'VERB': {'fin': 'VERB', 'inf': 'INFN', 'full_participle': 'PRTF', 'short_participle': 'PRTS', 'adverbial_participle': 'GRND'},\n",
    "    'NOUN': 'NOUN',\n",
    "    'PRON': 'NPRO',\n",
    "    'NUM': 'NUMR',\n",
    "    'CONJ': 'CONJ',\n",
    "    'INTJ': 'INTJ',\n",
    "    'DET': 'ADJF',\n",
    "    'PART': 'PRCL',\n",
    "    'ADP': 'PREP',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import Segmenter, MorphVocab, NewsEmbedding, NewsMorphTagger, Doc\n",
    "\n",
    "natasha_tags = {}\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "\n",
    "doc = Doc(data)\n",
    "doc.segment(segmenter)\n",
    "doc.tag_morph(morph_tagger)\n",
    "\n",
    "for t in doc.tokens:\n",
    "    if t.text in forms or t.text.lower() in forms:\n",
    "        if t.pos == 'VERB':\n",
    "            if 'Conv' in t.feats.values():\n",
    "                tag = natasha_pos['VERB']['adverbial_participle']\n",
    "            elif 'Part' in t.feats.values():\n",
    "                if 'Short' in t.feats.values():\n",
    "                    tag = natasha_pos['VERB']['short_participle']\n",
    "                else:\n",
    "                    tag = natasha_pos['VERB']['full_participle']\n",
    "            elif 'Inf' in t.feats.values():\n",
    "                tag = natasha_pos['VERB']['inf']\n",
    "        elif t.pos == 'ADJ':\n",
    "            if 'Short' in t.feats.values():\n",
    "                tag = natasha_pos['ADJ']['short']\n",
    "            elif 'Cmp' in t.feats.values():\n",
    "                tag = natasha_pos['ADJ']['compar']\n",
    "            else:\n",
    "                tag = natasha_pos['ADJ']['full']\n",
    "        elif t.pos == 'ADV':\n",
    "            if 'Cmp' in t.feats.values():\n",
    "                tag = natasha_pos['ADV']['compar']\n",
    "            else:\n",
    "                tag = natasha_pos['ADV']['positive']\n",
    "        else:\n",
    "            if t.pos in natasha_pos.keys():\n",
    "                tag = natasha_pos[t.pos]           \n",
    "            else:\n",
    "                tag = t.pos\n",
    "        natasha_tags[t.text] = tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечательно, что Natasha очень чувствительный к регистру анализатор. Если слово нарицательное, но первая его буква заглавная, то Natasha определяет его как \"PROPN\" (имя собственное), что реже наблюдается у других анализаторов (--> можно ожидать более низкое качество):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocToken(stop=5, text='Уснув', pos='PROPN', feats=<Anim,Nom,Masc,Sing>)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = Doc('Уснув, он забыл обо всем')\n",
    "doc.segment(segmenter)\n",
    "doc.tag_morph(morph_tagger)\n",
    "doc.tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocToken(stop=5, text='уснув', pos='NOUN', feats=<Inan,Nom,Masc,Sing>)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#здесь анализатор плохо справляется с деепричастием, после которого нет дополнения\n",
    "doc = Doc('уснув, он забыл обо всем')\n",
    "doc.segment(segmenter)\n",
    "doc.tag_morph(morph_tagger)\n",
    "doc.tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocToken(stop=6, text='Увидев', pos='PROPN', feats=<Anim,Nom,Masc,Sing>)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = Doc('Увидев')\n",
    "doc.segment(segmenter)\n",
    "doc.tag_morph(morph_tagger)\n",
    "doc.tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GRND'"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph.parse('уснув')[0].tag.POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GRND'"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph.parse('Увидев')[0].tag.POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(res_tags):\n",
    "    diffic['Словоформа'] = diffic['Словоформа'].apply(lambda x: x.lower())\n",
    "    right_tags = dict(zip(diffic.Словоформа, diffic.POS))\n",
    "    res_tags = {k.lower(): v for k, v in res_tags.items()}\n",
    "    right = 0\n",
    "    for key in res_tags.keys():\n",
    "        if type(right_tags[key]) != list:\n",
    "            if res_tags[key] == right_tags[key]:\n",
    "                right += 1\n",
    "        elif type(res_tags[key.lower()]) == list and type(right_tags[key.lower()]) != list:\n",
    "            if res_tags[key.lower()] == right_tags[key]:\n",
    "                right += 1\n",
    "    return [round(right/len(res_tags.keys()), 3), f'Верно: {right}, Неверно: {len(res_tags.keys())-right}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.737, 'Верно: 14, Неверно: 5']"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#точность pymorphy2\n",
    "compare(pymorphy2_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.421, 'Верно: 8, Неверно: 11']"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#точность natasha\n",
    "compare(natasha_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем проверить точность Наташи после приведения слов к нижнему регистру (чтобы избежать описанную в п. 2.3 проблему):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 'Верно: 9, Неверно: 9']"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natasha_tags = {}\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "\n",
    "doc = Doc(data.lower())\n",
    "doc.segment(segmenter)\n",
    "doc.tag_morph(morph_tagger)\n",
    "\n",
    "for t in doc.tokens:\n",
    "    if t.text in forms or t.text.lower() in forms:\n",
    "        if t.pos == 'VERB':\n",
    "            if 'Conv' in t.feats.values():\n",
    "                tag = natasha_pos['VERB']['adverbial_participle']\n",
    "            elif 'Part' in t.feats.values():\n",
    "                if 'Short' in t.feats.values():\n",
    "                    tag = natasha_pos['VERB']['short_participle']\n",
    "                else:\n",
    "                    tag = natasha_pos['VERB']['full_participle']\n",
    "            elif 'Inf' in t.feats.values():\n",
    "                tag = natasha_pos['VERB']['inf']\n",
    "        elif t.pos == 'ADJ':\n",
    "            if 'Short' in t.feats.values():\n",
    "                tag = natasha_pos['ADJ']['short']\n",
    "            elif 'Cmp' in t.feats.values():\n",
    "                tag = natasha_pos['ADJ']['compar']\n",
    "            else:\n",
    "                tag = natasha_pos['ADJ']['full']\n",
    "        elif t.pos == 'ADV':\n",
    "            if 'Cmp' in t.feats.values():\n",
    "                tag = natasha_pos['ADV']['compar']\n",
    "            else:\n",
    "                tag = natasha_pos['ADV']['positive']\n",
    "        else:\n",
    "            if t.pos in natasha_pos.keys():\n",
    "                tag = natasha_pos[t.pos]           \n",
    "            else:\n",
    "                tag = t.pos\n",
    "        natasha_tags[t.text] = tag\n",
    "\n",
    "compare(natasha_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.579, 'Верно: 11, Неверно: 8']"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#точность mystem\n",
    "compare(mystem_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> модели можно разместить в следующем по убыванию точности порядке:\n",
    "1) pymorphy2\n",
    "2) mystem\n",
    "3) natasha\n",
    "\n",
    "--> для следующей задачи используем Pymorphy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Chuncker**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачаем собранные и лемматизированные в предыдущей домашке тексты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#собранные с сайта отзывы\n",
    "data_full = pd.read_csv('hw1_data.csv', delimiter=',')\n",
    "del data_full['Unnamed: 0']\n",
    "data_full['Rate'] = data_full['Rate'].astype(int)\n",
    "data_full['Real'] = data_full['Rate'].apply(lambda x: 'положительный' if x > 3 else 'отрицательный')\n",
    "\n",
    "#лемматизированные данные\n",
    "data = pd.read_csv('hw1_all_data_tokens.csv', delimiter=',')\n",
    "del data['Unnamed: 0']\n",
    "data['Rate'] = data['Rate'].astype(int)\n",
    "data['Real'] = data['Rate'].apply(lambda x: 'положительный' if x > 3 else 'отрицательный')\n",
    "\n",
    "#при сохранении файла меняется тип данных в колонке Review, поэтому из строки нужно опять сделать список\n",
    "def clean_tokens(text):\n",
    "    text2 = []\n",
    "    for i in range(len(text)):\n",
    "        text[i] = re.sub(\"'|«|»|,| ,|, ,| \", '', text[i])\n",
    "        if text[i].isalpha():\n",
    "          text2.append(text[i])\n",
    "    return text2\n",
    "\n",
    "data['Review'] = data['Review'].apply(lambda x: x[1:-2].split(\"',\"))\n",
    "data['Review'] = data['Review'].apply(clean_tokens)\n",
    "data = data[data['Rate'] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>Фильм \"Черная вдова\" (2021)</td>\n",
       "      <td>[итак, начать, с, тот, что, данный, фильм, чёр...</td>\n",
       "      <td>4</td>\n",
       "      <td>положительный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>Фильм \"Бык\" (2019)</td>\n",
       "      <td>[приветствовать, весь, читатель, занлянуть, в,...</td>\n",
       "      <td>5</td>\n",
       "      <td>положительный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>Фильм \"Калашников\" (2020)</td>\n",
       "      <td>[биографический, фильм, калашников, решить, по...</td>\n",
       "      <td>2</td>\n",
       "      <td>отрицательный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>Фильм \"Поменяться местами\" (2019)</td>\n",
       "      <td>[добрый, день, сегодня, наткнуться, на, очень,...</td>\n",
       "      <td>5</td>\n",
       "      <td>положительный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>Фильм \"Вышка\" (2022)</td>\n",
       "      <td>[весь, привет, в, свой, сегодняшний, отзыв, я,...</td>\n",
       "      <td>4</td>\n",
       "      <td>положительный</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Name  \\\n",
       "1343        Фильм \"Черная вдова\" (2021)   \n",
       "1364                 Фильм \"Бык\" (2019)   \n",
       "2224          Фильм \"Калашников\" (2020)   \n",
       "1780  Фильм \"Поменяться местами\" (2019)   \n",
       "762                Фильм \"Вышка\" (2022)   \n",
       "\n",
       "                                                 Review  Rate           Real  \n",
       "1343  [итак, начать, с, тот, что, данный, фильм, чёр...     4  положительный  \n",
       "1364  [приветствовать, весь, читатель, занлянуть, в,...     5  положительный  \n",
       "2224  [биографический, фильм, калашников, решить, по...     2  отрицательный  \n",
       "1780  [добрый, день, сегодня, наткнуться, на, очень,...     5  положительный  \n",
       "762   [весь, привет, в, свой, сегодняшний, отзыв, я,...     4  положительный  "
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample = data.sample(frac=0.2)\n",
    "data_sample.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- тональный словарь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = data_sample[data_sample['Rate'] >= 4]['Review'].tolist()\n",
    "negative = data_sample[data_sample['Rate'] < 4]['Review'].tolist()\n",
    "positive = [element for each_list in positive for element in each_list]\n",
    "negative = [element for each_list in negative for element in each_list]\n",
    "only_positive = [x for x in positive if x not in negative]\n",
    "only_negative = [x for x in negative if x not in positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_positive_freq = []\n",
    "for word in only_positive:\n",
    "  if only_positive.count(word) > 2:\n",
    "    only_positive_freq.append(word)\n",
    "\n",
    "only_negative_freq = []\n",
    "for word in only_negative:\n",
    "  if only_negative.count(word) > 2:\n",
    "    only_negative_freq.append(word)\n",
    "\n",
    "only_positive_freq = set(only_positive_freq)\n",
    "only_negative_freq = set(only_negative_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- подсчет позитивных и негативных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(text):\n",
    "  positive_count = int()\n",
    "  negative_count = int()\n",
    "  for lemma in text:\n",
    "    if lemma in only_positive_freq:\n",
    "      positive_count += 1\n",
    "    elif lemma in only_negative_freq:\n",
    "      negative_count += 1\n",
    "  if positive_count > negative_count:\n",
    "    return 'положительный'\n",
    "  elif positive_count < negative_count:\n",
    "    return 'отрицательный'\n",
    "  else:\n",
    "    return 'нейтральный'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Верно: 462 Неверно: 68 Процент точности: 87.1698\n"
     ]
    }
   ],
   "source": [
    "data_sample = data.sample(frac=0.2)\n",
    "data_sample['Estimate'] = data_sample['Review'].apply(sentiment)\n",
    "#добавим разметку на основе звезд, присужденных каждому отзыву пользователем\n",
    "data_sample['Real'] = data_sample['Rate'].apply(lambda x: 'положительный' if x > 3 else 'отрицательный')\n",
    "\n",
    "stat = {'неверно': 0, 'верно': 0}\n",
    "for index, row in data_sample.iterrows():\n",
    "    if row['Estimate'] != row['Real']:\n",
    "      stat['неверно'] += 1\n",
    "    else:\n",
    "      stat['верно'] += 1\n",
    "\n",
    "print('Верно:', stat['верно'], 'Неверно:', stat['неверно'], 'Процент точности:', round(stat['верно']/(stat['верно']+stat['неверно'])*100, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Находим частотные биграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "pos_bigrams = {}\n",
    "neg_bigrams = {}\n",
    "\n",
    "for index, row in data_sample.iterrows():\n",
    "    bigrams = ngrams(row['Review'], 2)\n",
    "    if row['Real'] == 'положительный':\n",
    "        for b in bigrams:\n",
    "            if b not in pos_bigrams.keys():\n",
    "                pos_bigrams[b] = 1\n",
    "            else:\n",
    "                pos_bigrams[b] += 1\n",
    "    elif row['Real'] == 'отрицательный':\n",
    "        for b in bigrams:\n",
    "            if b not in neg_bigrams.keys():\n",
    "                neg_bigrams[b] = 1\n",
    "            else:\n",
    "                neg_bigrams[b] += 1\n",
    "\n",
    "def filter_dict(ngram_item):\n",
    "    key, value = ngram_item\n",
    "    if value > 4:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "pos_bigrams = dict(filter(filter_dict, pos_bigrams.items()))\n",
    "neg_bigrams = dict(filter(filter_dict, neg_bigrams.items()))\n",
    "\n",
    "pos_bigrams = dict(sorted(pos_bigrams.items(), key=lambda x: x[1], reverse=True))\n",
    "neg_bigrams = dict(sorted(neg_bigrams.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "pos_bigrams_filt = dict([x for x in pos_bigrams.items() if x[0] not in neg_bigrams.keys()])\n",
    "neg_bigrams_filt = dict([x for x in neg_bigrams.items() if x[0] not in pos_bigrams.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('не', 'рекомендовать'): 15,\n",
       " ('просмотр', 'не'): 7,\n",
       " ('потратить', 'время'): 6,\n",
       " ('не', 'понимать'): 6,\n",
       " ('то', 'ли'): 6,\n",
       " ('снять', 'фильм'): 5,\n",
       " ('с', 'весь'): 5,\n",
       " ('не', 'смешной'): 5,\n",
       " ('и', 'смотреть'): 5}"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(sorted(neg_bigrams_filt.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Заметим, что для негативных отзывов характерно сочетание частицы *не* с глаголом (нам необходимо найти как можно больше признаков негативных отзывов, т.к. тональный словарь для отрицательных текстов меньше, выборка несбалансированная (общая тенденция людей писать больше положительные отзывы)) (примеры: мне (не) нравится, я (не) рекомендую).\n",
    "\n",
    "2) Также можно рассмотреть группы \"глагол + наречие\", где один и тот же глагол в  сочетании с разными наречиями может давать как положительную, так и отрицательную окраску. Будем сравнивать частоту биграмм (биграммы про положительное, если ее частотность выше в положительных текстах), а если не получится, искать биграмму среди уникальных (создаем тональный словарь из биграмм).\n",
    "\n",
    "3) Усилительная частица *очень* в сочетании с прилигательным или наречием может давать яркую хар-ку объекту --> служить маркером тональности (проверяем, в каком списке (положительном или отрицательном) чаще всего появляется слово, после присваиваем +1 положительности или отрицательности).\n",
    "\n",
    "4) Можно проверить сочетания по типу *плохо* + VERB / VERB + *плохо* / *плохой* + NOUN (в зависимости от выборки может случайно отсечь наречие *плохо\" во 2ом пункте, поэтому такой очевидный маркер стоит рассмотреть отдельно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(text):\n",
    "    posit = int()\n",
    "    negat = int()\n",
    "    for i in range(len(text)-1):\n",
    "        if morph.parse(text[i])[0].tag.POS == 'INFN' and morph.parse(text[i+1])[0].tag.POS == 'ADVB':\n",
    "            #INFN, а не VERB, т.к. мы уже рассматриваем леммы\n",
    "            if (text[i], text[i+1]) in pos_bigrams.keys() and (text[i], text[i+1]) in neg_bigrams.keys():\n",
    "                if pos_bigrams[(text[i], text[i+1])] > neg_bigrams[(text[i], text[i+1])] and pos_bigrams[(text[i], text[i+1])]-neg_bigrams[(text[i], text[i+1])] > 2:\n",
    "                    posit += 1\n",
    "                elif pos_bigrams[(text[i], text[i+1])] < neg_bigrams[(text[i], text[i+1])] and neg_bigrams[(text[i], text[i+1])]-pos_bigrams[(text[i], text[i+1])] > 2:\n",
    "                    negat += 1\n",
    "               \n",
    "        elif (text[i] == 'не' and morph.parse(text[i+1])[0].tag.POS == 'INFN') or (text[i] == 'не' and morph.parse(text[i+1])[0].tag.POS == 'ADJF'):\n",
    "            if (text[i], text[i+1]) in pos_bigrams.keys() and (text[i], text[i+1]) in neg_bigrams.keys():\n",
    "                if pos_bigrams[(text[i], text[i+1])] > neg_bigrams[(text[i], text[i+1])] and pos_bigrams[(text[i], text[i+1])]-neg_bigrams[(text[i], text[i+1])] > 2:\n",
    "                    posit += 1\n",
    "                elif pos_bigrams[(text[i], text[i+1])] < neg_bigrams[(text[i], text[i+1])] and neg_bigrams[(text[i], text[i+1])]-pos_bigrams[(text[i], text[i+1])] > 2:\n",
    "                    negat += 1\n",
    "            elif (text[i], text[i+1]) in pos_bigrams_filt.keys():\n",
    "                posit += 1\n",
    "            elif (text[i], text[i+1]) in neg_bigrams_filt.keys():\n",
    "                negat += 1\n",
    "        elif text[i] == 'плохо' and morph.parse(text[i])[0].tag.POS == 'INFN':\n",
    "            negat += 1\n",
    "        \n",
    "        elif text[i] == 'плохой' and morph.parse(text[i])[0].tag.POS == 'NOUN':\n",
    "            negat += 1\n",
    "    \n",
    "        elif text[i] == 'очень' and (morph.parse(text[i+1])[0].tag.POS == 'ADJF' or morph.parse(text[i+1])[0].tag.POS == 'ADVB'):\n",
    "            if (text[i], text[i+1]) in pos_bigrams.keys() and (text[i], text[i+1]) in neg_bigrams.keys():\n",
    "                if pos_bigrams[(text[i], text[i+1])] > neg_bigrams[(text[i], text[i+1])] and pos_bigrams[(text[i], text[i+1])]-neg_bigrams[(text[i], text[i+1])] > 2:\n",
    "                    posit += 1\n",
    "                elif pos_bigrams[(text[i], text[i+1])] < neg_bigrams[(text[i], text[i+1])] and neg_bigrams[(text[i], text[i+1])]-pos_bigrams[(text[i], text[i+1])] > 2:\n",
    "                    negat += 1\n",
    "            elif text[i+1] in positive or text[i+1] in negative:\n",
    "                pos_count = positive.count(text[i+1])\n",
    "                neg_count = negative.count(text[i+1])\n",
    "                if pos_count > neg_count and pos_count-neg_count > 5:\n",
    "                    negat += 1\n",
    "                elif pos_count < neg_count and neg_count-pos_count > 5:\n",
    "                    posit += 1\n",
    "        \n",
    "    return [posit, negat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(text):\n",
    "  positive_count = int()\n",
    "  negative_count = int()\n",
    "  for lemma in text:\n",
    "    if lemma in only_positive_freq:\n",
    "      positive_count += 1\n",
    "    elif lemma in only_negative_freq:\n",
    "      negative_count += 1\n",
    "\n",
    "  bigrams_check = chunker(text)\n",
    "  positive_count += bigrams_check[0]\n",
    "  negative_count += bigrams_check[1]\n",
    "  \n",
    "  if positive_count > negative_count:\n",
    "    return 'положительный'\n",
    "  elif positive_count < negative_count:\n",
    "    return 'отрицательный'\n",
    "  else:\n",
    "    return 'нейтральный'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Верно: 478 Неверно: 52 Процент точности: 90.1887\n"
     ]
    }
   ],
   "source": [
    "data_sample = data.sample(frac=0.2)\n",
    "data_sample['Estimate'] = data_sample['Review'].apply(sentiment)\n",
    "#добавим разметку на основе звезд, присужденных каждому отзыву пользователем\n",
    "data_sample['Real'] = data_sample['Rate'].apply(lambda x: 'положительный' if x > 3 else 'отрицательный')\n",
    "\n",
    "stat = {'неверно': 0, 'верно': 0}\n",
    "for index, row in data_sample.iterrows():\n",
    "    if row['Estimate'] != row['Real']:\n",
    "      stat['неверно'] += 1\n",
    "    else:\n",
    "      stat['верно'] += 1\n",
    "\n",
    "print('Верно:', stat['верно'], 'Неверно:', stat['неверно'], 'Процент точности:', round(stat['верно']/(stat['верно']+stat['неверно'])*100, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также я проверяла биграмму *не* + *прилагательное* (среди отрицательных биграмм часто встречается отрицание положительного признака: не смешной момент, не интересный сюжет, и т.д.), где должна была усиливаться отрицательность высказывания, если прилагательное было положительным (положительность определялась кол-вом вхождений в положительный и отрицательный список), однако этот способ либо не приносил результата (существенно не повлиял на accuracy), либо уменьшал точность (так как выборки брались рандомные, то положительное, но редкое слово могло стать более популярным в отрицательных отзывах)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, качество модели повысилось на 2-3% за счет добавления возможности учитывать не только слова из тонального словаря, но и биграмм."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
